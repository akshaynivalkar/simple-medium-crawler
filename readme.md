# Simple Medium Crawler

Crawls medium.com and records all the crawled links in a text file (links.txt).

  - Install dependencies as given in installation below.
  - Crawler follows rules in [robots.txt].
  - Can replace starturl to crawl any other domain.

### Installation

Install the dependencies and run the script.

```sh
$ cd simple-medium-crawler
$ npm i
$ node crawler.js
```
Note - The links.txt file is cleared before every run.


[robots.txt]: <https://medium.com/robots.txt>
